message(sprintf("The Mean squared error of the random forest is %f", mseRand))
message(sprintf("Random forest with LOOCV cross validation statistics are:"))
message("Variable importance for the random forest with k-fold cross validation is:")
print(varImp(cv.fitRand$finalModel))
message(sprintf("Random forest with LOOCV cross validation statistic R^2 is %f", RsqCrossRand))
message(sprintf("Random forest with LOOCV cross validation statistic MAE is %f", MaeCrossRand))
message(sprintf("The Mean squared error of the k-fold cross validation random forest is %f", mseCrossRand))
message(sprintf("Random forest with hold-out cross validation statistics are:"))
message("Variable importance for the random forest with hold-out cross validation is:")
varImpPlot(rand.forest)
print(varImp(rand.forest))
message(sprintf("Random forest with hold-out cross validation statistic R^2 is %f", RsqRand))
message(sprintf("Random forest with hold-out cross validation statistic MAE is %f", MaeRand))
message(sprintf("The Mean squared error of the random forest is %f", mseRand))
message(sprintf("Random forest with LOOCV cross validation statistics are:"))
message("Variable importance for the random forest with k-fold cross validation is:")
varImpPlot(cv.fitRand$finalModel)
print(varImp(cv.fitRand$finalModel))
message(sprintf("Random forest with LOOCV cross validation statistic R^2 is %f", RsqCrossRand))
message(sprintf("Random forest with LOOCV cross validation statistic MAE is %f", MaeCrossRand))
message(sprintf("The Mean squared error of the k-fold cross validation random forest is %f", mseCrossRand))
library(ISLR2)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(Metrics)
library(rsq)
College_data = College_quant_data <- na.omit(College) %>%
mutate_all(~ if(is.factor(.)) {
as.numeric(as.factor(.))
} else {
.
})
par(mfrow = c(3, 3))
colnames = names(College_data)
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
set.seed(0)
alpha = 1
k = 10
lambda = 10^seq(10, -2, length = 100)
# Divide the data into training and test
x = model.matrix(Grad.Rate ~ ., data = College_data)[, -1]
y = College_data$Grad.Rate
trainIndex = createDataPartition(College_data$Grad.Rate, p = 0.7, list = FALSE)
training = na.omit(College_data[trainIndex, ])
testing = na.omit(College_data[-trainIndex, ])
#----------------------------------------------------------------
# Fit on training data
cv = trainControl(method = "cv", number = k)
shrink.mod = train(Grad.Rate ~ ., data = training, method = "glmnet", trControl = cv)
lm.fit = lm(Grad.Rate ~ ., data=training)
# glmnet is lasso
#----------------------------------------------
# Generalization Error
shrink.pred = predict(shrink.mod, testing)
MSE =  mean((testing$Grad.Rate - shrink.pred)^2)
Maek = mae(shrink.pred, testing$Grad.Rate)
Rsqk = R2(shrink.pred, testing$Grad.Rate)
shrink.pred = predict(lm.fit, testing)
MSElm =  mean((testing$Grad.Rate - shrink.pred)^2)
Maelm = mae(shrink.pred, testing$Grad.Rate)
Rsqlm = R2(shrink.pred, testing$Grad.Rate)
message("Metrics for for the decision linear regression with hold-out cross validation")
par(mfrow = c(2, 2))
plot(lm.fit)
print(varImp(lm.fit))
message(sprintf("Linear regression with hold-out cross validation statistic R^2 is %f", Rsqlm))
message(sprintf("Linear regression with hold-out cross validation statistic MAE is %f", Maelm))
message(sprintf("The Mean squared error of the linear regression with hold-out cross validation is %f", MSElm))
message("Metrics for for the Linear regression with k-fold cross validation and lasso fit")
summary(cv.fit$results)
plot(shrink.mod)
print(varImp(cv.fit$finalModel))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic R^2 is %f", Rsqk))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic MAE is %f", Maek))
message(sprintf("The Mean squared error of the linear regression with k-fold cross validation and lasso fit is %f", MSE))
library(rpart)
library(rpart.plot)
#----------------------------------------------------------------
# Fit a decision tree on the training data
fit.tree = rpart(Grad.Rate ~ ., data=training)
#------------------------------------------------
# preform cross validation to get the best fit
# Define tuning grid
tuneGrid = expand.grid(.cp = seq(0.01, 0.5, 0.01))
cv = trainControl(method = "LOOCV")
cv.fit = train(Grad.Rate ~ ., data = training, method = "rpart", trControl = cv, tuneGrid=tuneGrid)
#----------------------------------------------
# Generalization error
pred = predict(fit.tree, testing)
mseTree = mean((pred - testing$Grad.Rate)^2)
MaeTree = mae(pred, testing$Grad.Rate)
RsqTree = R2(pred, testing$Grad.Rate)
pred = predict(cv.fit, testing)
mseCrossTree = mean((pred - testing$Grad.Rate)^2)
MaeCrossTree = mae(pred, testing$Grad.Rate)
RsqCrossTree = R2(pred, testing$Grad.Rate)
message("Metrics for for the decision tree fit with hold-out cross validation")
rpart.plot(fit.tree)
print(varImp(fit.tree))
message(sprintf("Decision tree with hold-out cross validation statistic R^2 is %f", RsqTree))
message(sprintf("Decision tree with hold-out cross validation statistic MAE is %f", MaeTree))
message(sprintf("The Mean squared error of the decision tree with hold-out cross validation is %f", mseTree))
message("Metrics for for the decision tree with cross validation fit")
rpart.plot(cv.fit$finalModel)
print(varImp(cv.fit$finalModel))
message(sprintf("Decision tree with k-fold cross validation statistic R^2 is %f", RsqCrossTree))
message(sprintf("Decision tree with k-fold cross validation statistic MAE is %f", MaeCrossTree))
message(sprintf("The Mean squared error of the k-fold cross validation decision tree is %f", mseCrossTree))
# Already partitioned data for decision tree
library(randomForest)
#----------------------------------------------------------------
# Fit a random forest on the training data
rand.forest = randomForest(Grad.Rate ~ ., data = training, ntree = 500)
#------------------------------------------------
# preform cross validation to get the best fit
cv = trainControl(method = "cv", number = k)
cv.fitRand = train(Grad.Rate ~ ., data = training, method = "rf", trControl = cv, tuneLength=5) # TODO
#TODO
#----------------------------------------------
# Generalization error
pred = predict(rand.forest, testing)
mseRand = mean((pred - testing$Grad.Rate)^2)
MaeRand = mae(pred, testing$Grad.Rate)
RsqRand = R2(pred, testing$Grad.Rate)
pred = predict(cv.fitRand, testing)
mseCrossRand = mean((pred - testing$Grad.Rate)^2)
MaeCrossRand = mae(pred, testing$Grad.Rate)
RsqCrossRand = R2(pred, testing$Grad.Rate)
message(sprintf("Random forest with hold-out cross validation statistics are:"))
message("Variable importance for the random forest with hold-out cross validation is:")
varImpPlot(rand.forest)
print(varImp(rand.forest))
message(sprintf("Random forest with hold-out cross validation statistic R^2 is %f", RsqRand))
message(sprintf("Random forest with hold-out cross validation statistic MAE is %f", MaeRand))
message(sprintf("The Mean squared error of the random forest is %f", mseRand))
message(sprintf("Random forest with LOOCV cross validation statistics are:"))
message("Variable importance for the random forest with k-fold cross validation is:")
varImpPlot(cv.fitRand$finalModel)
print(varImp(cv.fitRand$finalModel))
message(sprintf("Random forest with LOOCV cross validation statistic R^2 is %f", RsqCrossRand))
message(sprintf("Random forest with LOOCV cross validation statistic MAE is %f", MaeCrossRand))
message(sprintf("The Mean squared error of the k-fold cross validation random forest is %f", mseCrossRand))
library(rpart)
library(rpart.plot)
#----------------------------------------------------------------
# Fit a decision tree on the training data
fit.tree = rpart(Grad.Rate ~ ., data=training)
#------------------------------------------------
# preform cross validation to get the best fit
# Define tuning grid
tuneGrid = expand.grid(.cp = seq(0, 1, 0.03))
cv = trainControl(method = "LOOCV")
cv.fit = train(Grad.Rate ~ ., data = training, method = "rpart", trControl = cv, tuneGrid=tuneGrid)
#----------------------------------------------
# Generalization error
pred = predict(fit.tree, testing)
mseTree = mean((pred - testing$Grad.Rate)^2)
MaeTree = mae(pred, testing$Grad.Rate)
RsqTree = R2(pred, testing$Grad.Rate)
pred = predict(cv.fit, testing)
mseCrossTree = mean((pred - testing$Grad.Rate)^2)
MaeCrossTree = mae(pred, testing$Grad.Rate)
RsqCrossTree = R2(pred, testing$Grad.Rate)
message("Metrics for for the decision tree fit with hold-out cross validation")
rpart.plot(fit.tree)
print(varImp(fit.tree))
message(sprintf("Decision tree with hold-out cross validation statistic R^2 is %f", RsqTree))
message(sprintf("Decision tree with hold-out cross validation statistic MAE is %f", MaeTree))
message(sprintf("The Mean squared error of the decision tree with hold-out cross validation is %f", mseTree))
message("Metrics for for the decision tree with cross validation fit")
rpart.plot(cv.fit$finalModel)
print(varImp(cv.fit$finalModel))
message(sprintf("Decision tree with k-fold cross validation statistic R^2 is %f", RsqCrossTree))
message(sprintf("Decision tree with k-fold cross validation statistic MAE is %f", MaeCrossTree))
message(sprintf("The Mean squared error of the k-fold cross validation decision tree is %f", mseCrossTree))
library(rpart)
library(rpart.plot)
#----------------------------------------------------------------
# Fit a decision tree on the training data
fit.tree = rpart(Grad.Rate ~ ., data=training)
#------------------------------------------------
# preform cross validation to get the best fit
# Define tuning grid
tuneGrid = expand.grid(.cp = seq(0, 1, 0.01))
cv = trainControl(method = "LOOCV")
cv.fit = train(Grad.Rate ~ ., data = training, method = "rpart", trControl = cv, tuneGrid=tuneGrid)
#----------------------------------------------
# Generalization error
pred = predict(fit.tree, testing)
mseTree = mean((pred - testing$Grad.Rate)^2)
MaeTree = mae(pred, testing$Grad.Rate)
RsqTree = R2(pred, testing$Grad.Rate)
pred = predict(cv.fit, testing)
mseCrossTree = mean((pred - testing$Grad.Rate)^2)
MaeCrossTree = mae(pred, testing$Grad.Rate)
RsqCrossTree = R2(pred, testing$Grad.Rate)
message("Metrics for for the decision tree fit with hold-out cross validation")
rpart.plot(fit.tree)
print(varImp(fit.tree))
message(sprintf("Decision tree with hold-out cross validation statistic R^2 is %f", RsqTree))
message(sprintf("Decision tree with hold-out cross validation statistic MAE is %f", MaeTree))
message(sprintf("The Mean squared error of the decision tree with hold-out cross validation is %f", mseTree))
message("Metrics for for the decision tree with cross validation fit")
rpart.plot(cv.fit$finalModel)
print(varImp(cv.fit$finalModel))
message(sprintf("Decision tree with k-fold cross validation statistic R^2 is %f", RsqCrossTree))
message(sprintf("Decision tree with k-fold cross validation statistic MAE is %f", MaeCrossTree))
message(sprintf("The Mean squared error of the k-fold cross validation decision tree is %f", mseCrossTree))
library(ISLR2)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(Metrics)
library(rsq)
College_data = College_quant_data <- na.omit(College) %>%
mutate_all(~ if(is.factor(.)) {
as.numeric(as.factor(.))
} else {
.
})
par(mfrow = c(3, 3))
colnames = names(College_data)
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
set.seed(0)
alpha = 1
k = 10
lambda = 10^seq(10, -2, length = 100)
# Divide the data into training and test
x = model.matrix(Grad.Rate ~ ., data = College_data)[, -1]
y = College_data$Grad.Rate
trainIndex = createDataPartition(College_data$Grad.Rate, p = 0.7, list = FALSE)
training = na.omit(College_data[trainIndex, ])
testing = na.omit(College_data[-trainIndex, ])
#----------------------------------------------------------------
# Fit on training data
cv = trainControl(method = "cv", number = k)
shrink.mod = train(Grad.Rate ~ ., data = training, method = "glmnet", trControl = cv)
lm.fit = lm(Grad.Rate ~ ., data=training)
# glmnet is lasso
#----------------------------------------------
# Generalization Error
shrink.pred = predict(shrink.mod, testing)
MSE =  mean((testing$Grad.Rate - shrink.pred)^2)
Maek = mae(shrink.pred, testing$Grad.Rate)
Rsqk = R2(shrink.pred, testing$Grad.Rate)
shrink.pred = predict(lm.fit, testing)
MSElm =  mean((testing$Grad.Rate - shrink.pred)^2)
Maelm = mae(shrink.pred, testing$Grad.Rate)
Rsqlm = R2(shrink.pred, testing$Grad.Rate)
message("Metrics for for the decision linear regression with hold-out cross validation")
par(mfrow = c(2, 2))
plot(lm.fit)
print(varImp(lm.fit))
message(sprintf("Linear regression with hold-out cross validation statistic R^2 is %f", Rsqlm))
message(sprintf("Linear regression with hold-out cross validation statistic MAE is %f", Maelm))
message(sprintf("The Mean squared error of the linear regression with hold-out cross validation is %f", MSElm))
message("Metrics for for the Linear regression with k-fold cross validation and lasso fit")
summary(cv.fit$results)
plot(shrink.mod)
print(varImp(cv.fit$finalModel))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic R^2 is %f", Rsqk))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic MAE is %f", Maek))
message(sprintf("The Mean squared error of the linear regression with k-fold cross validation and lasso fit is %f", MSE))
library(rpart)
library(rpart.plot)
#----------------------------------------------------------------
# Fit a decision tree on the training data
fit.tree = rpart(Grad.Rate ~ ., data=training)
#------------------------------------------------
# preform cross validation to get the best fit
# Define tuning grid
tuneGrid = expand.grid(.cp = seq(0, 1, 0.01))
cv = trainControl(method = "LOOCV")
cv.fit = train(Grad.Rate ~ ., data = training, method = "rpart", trControl = cv, tuneGrid=tuneGrid)
#----------------------------------------------
# Generalization error
pred = predict(fit.tree, testing)
mseTree = mean((pred - testing$Grad.Rate)^2)
MaeTree = mae(pred, testing$Grad.Rate)
RsqTree = R2(pred, testing$Grad.Rate)
pred = predict(cv.fit, testing)
mseCrossTree = mean((pred - testing$Grad.Rate)^2)
MaeCrossTree = mae(pred, testing$Grad.Rate)
RsqCrossTree = R2(pred, testing$Grad.Rate)
message("Metrics for for the decision tree fit with hold-out cross validation")
rpart.plot(fit.tree)
print(varImp(fit.tree))
message(sprintf("Decision tree with hold-out cross validation statistic R^2 is %f", RsqTree))
message(sprintf("Decision tree with hold-out cross validation statistic MAE is %f", MaeTree))
message(sprintf("The Mean squared error of the decision tree with hold-out cross validation is %f", mseTree))
message("Metrics for for the decision tree with cross validation fit")
rpart.plot(cv.fit$finalModel)
print(varImp(cv.fit$finalModel))
message(sprintf("Decision tree with k-fold cross validation statistic R^2 is %f", RsqCrossTree))
message(sprintf("Decision tree with k-fold cross validation statistic MAE is %f", MaeCrossTree))
message(sprintf("The Mean squared error of the k-fold cross validation decision tree is %f", mseCrossTree))
# Already partitioned data for decision tree
library(randomForest)
#----------------------------------------------------------------
# Fit a random forest on the training data
rand.forest = randomForest(Grad.Rate ~ ., data = training, ntree = 500)
#------------------------------------------------
# preform cross validation to get the best fit
cv = trainControl(method = "cv", number = k)
cv.fitRand = train(Grad.Rate ~ ., data = training, method = "rf", trControl = cv, tuneLength=5) # TODO
#TODO
#----------------------------------------------
# Generalization error
pred = predict(rand.forest, testing)
mseRand = mean((pred - testing$Grad.Rate)^2)
MaeRand = mae(pred, testing$Grad.Rate)
RsqRand = R2(pred, testing$Grad.Rate)
pred = predict(cv.fitRand, testing)
mseCrossRand = mean((pred - testing$Grad.Rate)^2)
MaeCrossRand = mae(pred, testing$Grad.Rate)
RsqCrossRand = R2(pred, testing$Grad.Rate)
message(sprintf("Random forest with hold-out cross validation statistics are:"))
message("Variable importance for the random forest with hold-out cross validation is:")
varImpPlot(rand.forest)
print(varImp(rand.forest))
message(sprintf("Random forest with hold-out cross validation statistic R^2 is %f", RsqRand))
message(sprintf("Random forest with hold-out cross validation statistic MAE is %f", MaeRand))
message(sprintf("The Mean squared error of the random forest is %f", mseRand))
message(sprintf("Random forest with LOOCV cross validation statistics are:"))
message("Variable importance for the random forest with k-fold cross validation is:")
varImpPlot(cv.fitRand$finalModel)
print(varImp(cv.fitRand$finalModel))
message(sprintf("Random forest with LOOCV cross validation statistic R^2 is %f", RsqCrossRand))
message(sprintf("Random forest with LOOCV cross validation statistic MAE is %f", MaeCrossRand))
message(sprintf("The Mean squared error of the k-fold cross validation random forest is %f", mseCrossRand))
par(mfrow = c(3, 3))
colnames = names(College_data)
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
hist(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
par(mfrow = c(3, 3))
colnames = names(College_data)
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
hist(College[,i], College_data$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
par(mfrow = c(3, 3))
colnames = names(College_data)
hist(College_data$Grad.Rate, col = "blue", main = "Graduation Rates")
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
colnames = names(College_data)
hist(College_data$Grad.Rate, col = "blue", main = "Graduation Rates")
par(mfrow = c(3, 3))
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
colnames = names(College_data)
message(sprintf("The mean of Grad.Rate is %f", mean(College_data$Grad.Rate)))
message(sprintf("The standard deviation of Grad.Rate is %f", stdev(College_data$Grad.Rate)))
colnames = names(College_data)
message(sprintf("The mean of Grad.Rate is %f", mean(College_data$Grad.Rate)))
message(sprintf("The standard deviation of Grad.Rate is %f", sd(College_data$Grad.Rate)))
hist(College_data$Grad.Rate, col = "blue", main = "Graduation Rates")
par(mfrow = c(3, 3))
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
library(ISLR2)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(Metrics)
library(rsq)
College_data = College_quant_data <- na.omit(College) %>%
mutate_all(~ if(is.factor(.)) {
as.numeric(as.factor(.))
} else {
.
})
colnames = names(College_data)
message(sprintf("The mean of Grad.Rate is %f", mean(College_data$Grad.Rate)))
message(sprintf("The standard deviation of Grad.Rate is %f", sd(College_data$Grad.Rate)))
hist(College_data$Grad.Rate, col = "blue", main = "Graduation Rates")
par(mfrow = c(3, 3))
for (i in 2:length(colnames) - 1) {
# make scatter plot of Grad.Rate against the current predictor
plot(College[,i], College$Grad.Rate, xlab = colnames[i], ylab = "Grad.Rate")
}
cor(College_data)[- which(colnames(College) == "Grad.Rate"), "Grad.Rate"] # print out correlations except the grad to grad
set.seed(0)
alpha = 1
k = 10
lambda = 10^seq(10, -2, length = 100)
# Divide the data into training and test
x = model.matrix(Grad.Rate ~ ., data = College_data)[, -1]
y = College_data$Grad.Rate
trainIndex = createDataPartition(College_data$Grad.Rate, p = 0.7, list = FALSE)
training = na.omit(College_data[trainIndex, ])
testing = na.omit(College_data[-trainIndex, ])
#----------------------------------------------------------------
# Fit on training data
cv = trainControl(method = "cv", number = k)
shrink.mod = train(Grad.Rate ~ ., data = training, method = "glmnet", trControl = cv)
lm.fit = lm(Grad.Rate ~ ., data=training)
# glmnet is lasso
#----------------------------------------------
# Generalization Error
shrink.pred = predict(shrink.mod, testing)
MSE =  mean((testing$Grad.Rate - shrink.pred)^2)
Maek = mae(shrink.pred, testing$Grad.Rate)
Rsqk = R2(shrink.pred, testing$Grad.Rate)
shrink.pred = predict(lm.fit, testing)
MSElm =  mean((testing$Grad.Rate - shrink.pred)^2)
Maelm = mae(shrink.pred, testing$Grad.Rate)
Rsqlm = R2(shrink.pred, testing$Grad.Rate)
message("Metrics for for the decision linear regression with hold-out cross validation")
par(mfrow = c(2, 2))
plot(lm.fit)
print(varImp(lm.fit))
message(sprintf("Linear regression with hold-out cross validation statistic R^2 is %f", Rsqlm))
message(sprintf("Linear regression with hold-out cross validation statistic MAE is %f", Maelm))
message(sprintf("The Mean squared error of the linear regression with hold-out cross validation is %f", MSElm))
message("Metrics for for the Linear regression with k-fold cross validation and lasso fit")
summary(cv.fit$results)
plot(shrink.mod)
print(varImp(cv.fit$finalModel))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic R^2 is %f", Rsqk))
message(sprintf("Linear regression with k-fold cross validation and lasso statistic MAE is %f", Maek))
message(sprintf("The Mean squared error of the linear regression with k-fold cross validation and lasso fit is %f", MSE))
library(rpart)
library(rpart.plot)
#----------------------------------------------------------------
# Fit a decision tree on the training data
fit.tree = rpart(Grad.Rate ~ ., data=training)
#------------------------------------------------
# preform cross validation to get the best fit
# Define tuning grid
tuneGrid = expand.grid(.cp = seq(0, 1, 0.01))
cv = trainControl(method = "LOOCV")
cv.fit = train(Grad.Rate ~ ., data = training, method = "rpart", trControl = cv, tuneGrid=tuneGrid)
#----------------------------------------------
# Generalization error
pred = predict(fit.tree, testing)
mseTree = mean((pred - testing$Grad.Rate)^2)
MaeTree = mae(pred, testing$Grad.Rate)
RsqTree = R2(pred, testing$Grad.Rate)
pred = predict(cv.fit, testing)
mseCrossTree = mean((pred - testing$Grad.Rate)^2)
MaeCrossTree = mae(pred, testing$Grad.Rate)
RsqCrossTree = R2(pred, testing$Grad.Rate)
message("Metrics for for the decision tree fit with hold-out cross validation")
rpart.plot(fit.tree)
print(varImp(fit.tree))
message(sprintf("Decision tree with hold-out cross validation statistic R^2 is %f", RsqTree))
message(sprintf("Decision tree with hold-out cross validation statistic MAE is %f", MaeTree))
message(sprintf("The Mean squared error of the decision tree with hold-out cross validation is %f", mseTree))
message("Metrics for for the decision tree with cross validation fit")
rpart.plot(cv.fit$finalModel)
print(varImp(cv.fit$finalModel))
message(sprintf("Decision tree with k-fold cross validation statistic R^2 is %f", RsqCrossTree))
message(sprintf("Decision tree with k-fold cross validation statistic MAE is %f", MaeCrossTree))
message(sprintf("The Mean squared error of the k-fold cross validation decision tree is %f", mseCrossTree))
# Already partitioned data for decision tree
library(randomForest)
#----------------------------------------------------------------
# Fit a random forest on the training data
rand.forest = randomForest(Grad.Rate ~ ., data = training, ntree = 500)
#------------------------------------------------
# preform cross validation to get the best fit
cv = trainControl(method = "cv", number = k)
cv.fitRand = train(Grad.Rate ~ ., data = training, method = "rf", trControl = cv, tuneLength=5) # TODO
#TODO
#----------------------------------------------
# Generalization error
pred = predict(rand.forest, testing)
mseRand = mean((pred - testing$Grad.Rate)^2)
MaeRand = mae(pred, testing$Grad.Rate)
RsqRand = R2(pred, testing$Grad.Rate)
pred = predict(cv.fitRand, testing)
mseCrossRand = mean((pred - testing$Grad.Rate)^2)
MaeCrossRand = mae(pred, testing$Grad.Rate)
RsqCrossRand = R2(pred, testing$Grad.Rate)
message(sprintf("Random forest with hold-out cross validation statistics are:"))
message("Variable importance for the random forest with hold-out cross validation is:")
varImpPlot(rand.forest)
print(varImp(rand.forest))
message(sprintf("Random forest with hold-out cross validation statistic R^2 is %f", RsqRand))
message(sprintf("Random forest with hold-out cross validation statistic MAE is %f", MaeRand))
message(sprintf("The Mean squared error of the random forest is %f", mseRand))
message(sprintf("Random forest with LOOCV cross validation statistics are:"))
message("Variable importance for the random forest with k-fold cross validation is:")
varImpPlot(cv.fitRand$finalModel)
print(varImp(cv.fitRand$finalModel))
message(sprintf("Random forest with LOOCV cross validation statistic R^2 is %f", RsqCrossRand))
message(sprintf("Random forest with LOOCV cross validation statistic MAE is %f", MaeCrossRand))
message(sprintf("The Mean squared error of the k-fold cross validation random forest is %f", mseCrossRand))
